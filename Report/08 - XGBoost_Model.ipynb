{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import mean_absolute_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      IMDbRating  Year  Action  Adult  Adventure  Animation  Biography  \\\n",
      "0            7.1  2000       0      0          0          0          0   \n",
      "1            4.1  2000       0      0          0          0          0   \n",
      "2            6.6  2000       0      0          1          0          0   \n",
      "3            5.6  2000       0      0          0          0          0   \n",
      "4            7.7  2000       0      0          0          0          0   \n",
      "...          ...   ...     ...    ...        ...        ...        ...   \n",
      "6509         4.0  2022       0      0          0          0          0   \n",
      "6510         7.9  2022       0      0          1          1          0   \n",
      "6511         7.6  2022       0      0          0          0          0   \n",
      "6512         6.9  2022       0      0          0          0          1   \n",
      "6513         6.7  2022       0      0          0          0          0   \n",
      "\n",
      "      Comedy  Crime  Documentary  ...  Unnamed: 0        t1        t2  \\\n",
      "0          0      0            0  ...           0  0.512950  0.114857   \n",
      "1          0      0            0  ...           1  0.054331  0.054315   \n",
      "2          0      0            0  ...           2  0.039721  0.237527   \n",
      "3          1      0            0  ...           3  0.513904  0.098898   \n",
      "4          0      0            0  ...           4  0.044343  0.046531   \n",
      "...      ...    ...          ...  ...         ...       ...       ...   \n",
      "6509       0      0            0  ...        6509  0.252224  0.051825   \n",
      "6510       1      0            0  ...        6510  0.058088  0.048866   \n",
      "6511       1      0            0  ...        6511  0.056763  0.057261   \n",
      "6512       0      0            0  ...        6512  0.050757  0.052328   \n",
      "6513       0      1            0  ...        6513  0.170601  0.076896   \n",
      "\n",
      "            t3        t4        t5        t6        t7        t8        t9  \n",
      "0     0.023082  0.024851  0.032014  0.084131  0.060399  0.047861  0.099853  \n",
      "1     0.061806  0.095144  0.068057  0.477110  0.054117  0.077907  0.057213  \n",
      "2     0.038066  0.082043  0.074964  0.048033  0.217987  0.227335  0.034323  \n",
      "3     0.042445  0.034457  0.044801  0.039667  0.039551  0.118835  0.067442  \n",
      "4     0.028705  0.027482  0.298594  0.191709  0.173903  0.026904  0.161827  \n",
      "...        ...       ...       ...       ...       ...       ...       ...  \n",
      "6509  0.071439  0.052529  0.052125  0.110842  0.050760  0.303895  0.054362  \n",
      "6510  0.053231  0.074877  0.102638  0.079078  0.078468  0.439172  0.065582  \n",
      "6511  0.058586  0.058671  0.274291  0.059230  0.273952  0.061321  0.099925  \n",
      "6512  0.055337  0.088915  0.113313  0.049831  0.458770  0.078949  0.051801  \n",
      "6513  0.213457  0.036051  0.071391  0.047748  0.064054  0.283878  0.035924  \n",
      "\n",
      "[6514 rows x 966 columns]\n"
     ]
    }
   ],
   "source": [
    "df1 = pd.read_csv(\"Data/PreProcessedData.csv\")\n",
    "df_no_plot = df1.drop('Plot', axis = 1)\n",
    "df2 = pd.read_csv(\"Data/LDA_topics.csv\") #UPDATE THIS TO BE WHATEVER DATA WE GIVE IT\n",
    "df_LDATOPICS = pd.concat([df_no_plot, df2], axis=1)\n",
    "df_LDATOPICS = df_LDATOPICS.drop('Title', axis = 1)\n",
    "print(df_LDATOPICS)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "outputs": [],
   "source": [
    "df2 = pd.read_csv(\"Data/LDA_topics_synonym.csv\")\n",
    "df_LDATOPICS_synonym = pd.concat([df_no_plot, df2], axis=1)\n",
    "df_LDATOPICS_synonym = df_LDATOPICS_synonym.drop('Title', axis = 1)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "outputs": [],
   "source": [
    "def test_trainsets(df):\n",
    "    rating = df['IMDbRating']\n",
    "    xdf = df.drop('IMDbRating', axis=1, inplace=False)\n",
    "    \n",
    "    # Split the data into train and test sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(xdf, rating, test_size=0.2, random_state=42)\n",
    "    \n",
    "    X_train_df = pd.DataFrame(X_train)\n",
    "    X_test_df = pd.DataFrame(X_test)\n",
    "    y_train_df = pd.DataFrame(y_train)\n",
    "    y_test_df = pd.DataFrame(y_test)\n",
    "\n",
    "    return X_train_df, y_train_df, X_test_df, y_test_df"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "outputs": [],
   "source": [
    "#ROOM FOR PARAMETER TESTING"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE: 0.678209176159545\n",
      "Baseline: 0.776840421462601\n",
      "MAE: 0.732682787022069\n",
      "Baseline: 0.8239868527045442\n",
      "MAE: 0.7345483812855668\n",
      "Baseline: 0.8302755760643642\n",
      "MAE: 0.6901474795277426\n",
      "Baseline: 0.7796659473113684\n",
      "MAE: 0.7152102596700306\n",
      "Baseline: 0.8062892206100271\n",
      "Average MAE over training: 0.7101596167329908\n",
      "Average Baseline over training: 0.803411603630581\n"
     ]
    }
   ],
   "source": [
    "X_train, y_train, X_test, y_test = test_trainsets(df_LDATOPICS)\n",
    "\n",
    "# Create the XGBoost model\n",
    "xgb_model = xgb.XGBRegressor()\n",
    "\n",
    "# Kfold\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=123)\n",
    "\n",
    "# store the score for each fold\n",
    "scores = []\n",
    "\n",
    "mae_scores = []\n",
    "baseline_scores = []\n",
    "# Iterate over the folds\n",
    "for train_index, val_index in kf.split(X_train):\n",
    "    # Split the data into training and validation sets\n",
    "    X_train_fold, X_val_fold = X_train.iloc[train_index], X_train.iloc[val_index]\n",
    "    y_train_fold, y_val_fold = y_train.iloc[train_index], y_train.iloc[val_index]\n",
    "\n",
    "    # Train the model on the training data\n",
    "    xgb_model.fit(X_train_fold, y_train_fold)\n",
    "\n",
    "    # Make predictions on the validation data\n",
    "    y_pred_fold = xgb_model.predict(X_val_fold)\n",
    "    # Compute the MAE score\n",
    "    baseline = mean_absolute_error(y_val_fold, np.array([np.mean(y_train['IMDbRating'])] * len(y_pred_fold)))\n",
    "    mae = mean_absolute_error(y_val_fold, y_pred_fold)\n",
    "    print(f\"MAE: {mae}\")\n",
    "    print(f\"Baseline: {baseline}\")\n",
    "    mae_scores.append(mae)\n",
    "    baseline_scores.append(baseline)\n",
    "\n",
    "# Compute the average MAE score\n",
    "average_mae_LDA = sum(mae_scores) / len(mae_scores)\n",
    "average_baseline = sum(baseline_scores) / len(baseline_scores)\n",
    "print(f\"Average MAE over training: {average_mae_LDA}\")\n",
    "print(f\"Average Baseline over training: {average_baseline}\")\n",
    "y_pred = xgb_model.predict(X_test)\n",
    "test_score_LDA = mean_absolute_error(y_pred, y_test)\n",
    "results = pd.DataFrame({'Actual': y_test['IMDbRating'], 'Prediction': y_pred})\n",
    "results.to_csv('LDA_Topics_results.csv', index=False)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE: 0.6905952620026249\n",
      "Baseline: 0.776840421462601\n",
      "MAE: 0.7194052845868862\n",
      "Baseline: 0.8239868527045442\n",
      "MAE: 0.7220759663609305\n",
      "Baseline: 0.8302755760643642\n",
      "MAE: 0.6922737716484436\n",
      "Baseline: 0.7796659473113684\n",
      "MAE: 0.7190202249446437\n",
      "Baseline: 0.8062892206100271\n",
      "Average MAE over training: 0.7086741019087058\n",
      "Average Baseline over training: 0.803411603630581\n"
     ]
    }
   ],
   "source": [
    "X_train, y_train, X_test, y_test = test_trainsets(df_LDATOPICS_synonym)\n",
    "\n",
    "# Create the XGBoost model\n",
    "xgb_model = xgb.XGBRegressor()\n",
    "\n",
    "# Kfold\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=123)\n",
    "\n",
    "# store the score for each fold\n",
    "scores = []\n",
    "\n",
    "mae_scores = []\n",
    "baseline_scores = []\n",
    "# Iterate over the folds\n",
    "for train_index, val_index in kf.split(X_train):\n",
    "    # Split the data into training and validation sets\n",
    "    X_train_fold, X_val_fold = X_train.iloc[train_index], X_train.iloc[val_index]\n",
    "    y_train_fold, y_val_fold = y_train.iloc[train_index], y_train.iloc[val_index]\n",
    "\n",
    "    # Train the model on the training data\n",
    "    xgb_model.fit(X_train_fold, y_train_fold)\n",
    "\n",
    "    # Make predictions on the validation data\n",
    "    y_pred_fold = xgb_model.predict(X_val_fold)\n",
    "    # Compute the MAE score\n",
    "    baseline = mean_absolute_error(y_val_fold, np.array([np.mean(y_train['IMDbRating'])] * len(y_pred_fold)))\n",
    "    mae = mean_absolute_error(y_val_fold, y_pred_fold)\n",
    "    print(f\"MAE: {mae}\")\n",
    "    print(f\"Baseline: {baseline}\")\n",
    "    mae_scores.append(mae)\n",
    "    baseline_scores.append(baseline)\n",
    "\n",
    "# Compute the average MAE score\n",
    "average_mae_LDASynonym = sum(mae_scores) / len(mae_scores)\n",
    "average_baseline = sum(baseline_scores) / len(baseline_scores)\n",
    "\n",
    "print(f\"Average MAE over training: {average_mae_LDASynonym}\")\n",
    "print(f\"Average Baseline over training: {average_baseline}\")\n",
    "y_pred = xgb_model.predict(X_test)\n",
    "test_score_LDA_synonym = mean_absolute_error(y_pred, y_test)\n",
    "results = pd.DataFrame({'Actual': y_test['IMDbRating'], 'Prediction': y_pred})\n",
    "results.to_csv('LDA_Topics_synonym_results.csv', index=False)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE: 0.7065315148745835\n",
      "Baseline: 0.776840421462601\n",
      "MAE: 0.7376345328772137\n",
      "Baseline: 0.8239868527045442\n",
      "MAE: 0.7452298975265415\n",
      "Baseline: 0.8302755760643642\n",
      "MAE: 0.7045498759183683\n",
      "Baseline: 0.7796659473113684\n",
      "MAE: 0.7379685519981749\n",
      "Baseline: 0.8062892206100271\n",
      "Average MAE over training: 0.7263828746389762\n",
      "Average Baseline over training: 0.803411603630581\n"
     ]
    }
   ],
   "source": [
    "df_HFTransformer = pd.read_csv(\"Data/PreProcessedData_with_HF_embeddings.csv\")\n",
    "X_train, y_train, X_test, y_test = test_trainsets(df_HFTransformer)\n",
    "\n",
    "# Create the XGBoost model\n",
    "xgb_model = xgb.XGBRegressor()\n",
    "\n",
    "# Kfold\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=123)\n",
    "\n",
    "# store the score for each fold\n",
    "scores = []\n",
    "\n",
    "mae_scores = []\n",
    "baseline_scores = []\n",
    "# Iterate over the folds\n",
    "for train_index, val_index in kf.split(X_train):\n",
    "    # Split the data into training and validation sets\n",
    "    X_train_fold, X_val_fold = X_train.iloc[train_index], X_train.iloc[val_index]\n",
    "    y_train_fold, y_val_fold = y_train.iloc[train_index], y_train.iloc[val_index]\n",
    "\n",
    "    # Train the model on the training data\n",
    "    xgb_model.fit(X_train_fold, y_train_fold)\n",
    "\n",
    "    # Make predictions on the validation data\n",
    "    y_pred_fold = xgb_model.predict(X_val_fold)\n",
    "    # Compute the MAE score\n",
    "    baseline = mean_absolute_error(y_val_fold, np.array([np.mean(y_train['IMDbRating'])] * len(y_pred_fold)))\n",
    "    mae = mean_absolute_error(y_val_fold, y_pred_fold)\n",
    "    print(f\"MAE: {mae}\")\n",
    "    print(f\"Baseline: {baseline}\")\n",
    "    mae_scores.append(mae)\n",
    "    baseline_scores.append(baseline)\n",
    "\n",
    "# Compute the average MAE score\n",
    "average_mae_HF = sum(mae_scores) / len(mae_scores)\n",
    "average_baseline = sum(baseline_scores) / len(baseline_scores)\n",
    "\n",
    "print(f\"Average MAE over training: {average_mae_HF}\")\n",
    "print(f\"Average Baseline over training: {average_baseline}\")\n",
    "y_pred = xgb_model.predict(X_test)\n",
    "test_score_HF = mean_absolute_error(y_pred, y_test)\n",
    "results = pd.DataFrame({'Actual': y_test['IMDbRating'], 'Prediction': y_pred})\n",
    "\n",
    "results.to_csv('HF_Transformer_Model_Results.csv', index=False)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAINING AVERAGE MAE\n",
      "HuggingFaceTransformer: 0.7263828746389762, LDA: 0.7101596167329908, LDA with synonyms: 0.7086741019087058, Baseline: 0.803411603630581\n",
      "TEST MAE\n",
      "HuggingFaceTransformer: 0.7603872038269629, LDA: 0.7250767980825874, LDA with synonyms: 0.7157429137050603, Baseline: 0.8261005226413869\n"
     ]
    }
   ],
   "source": [
    "print(\"TRAINING AVERAGE MAE\")\n",
    "print(f\"HuggingFaceTransformer: {average_mae_HF}, LDA: {average_mae_LDA}, LDA with synonyms: {average_mae_LDASynonym}, Baseline: {average_baseline}\")\n",
    "print(\"TEST MAE\")\n",
    "print(f\"HuggingFaceTransformer: {test_score_HF}, LDA: {test_score_LDA}, LDA with synonyms: {test_score_LDA_synonym}, Baseline: {mean_absolute_error(y_test, np.array([np.mean(y_train['IMDbRating'])] * len(y_test)))}\")\n"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
