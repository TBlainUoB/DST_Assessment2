{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import mean_absolute_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      IMDbRating  Year  Action  Adult  Adventure  Animation  Biography  \\\n",
      "0            7.1  2000       0      0          0          0          0   \n",
      "1            4.1  2000       0      0          0          0          0   \n",
      "2            6.6  2000       0      0          1          0          0   \n",
      "3            5.6  2000       0      0          0          0          0   \n",
      "4            7.7  2000       0      0          0          0          0   \n",
      "...          ...   ...     ...    ...        ...        ...        ...   \n",
      "6509         4.0  2022       0      0          0          0          0   \n",
      "6510         7.9  2022       0      0          1          1          0   \n",
      "6511         7.6  2022       0      0          0          0          0   \n",
      "6512         6.9  2022       0      0          0          0          1   \n",
      "6513         6.7  2022       0      0          0          0          0   \n",
      "\n",
      "      Comedy  Crime  Documentary  ...  Unnamed: 0        t1        t2  \\\n",
      "0          0      0            0  ...           0  0.512950  0.114857   \n",
      "1          0      0            0  ...           1  0.054331  0.054315   \n",
      "2          0      0            0  ...           2  0.039721  0.237527   \n",
      "3          1      0            0  ...           3  0.513904  0.098898   \n",
      "4          0      0            0  ...           4  0.044343  0.046531   \n",
      "...      ...    ...          ...  ...         ...       ...       ...   \n",
      "6509       0      0            0  ...        6509  0.252224  0.051825   \n",
      "6510       1      0            0  ...        6510  0.058088  0.048866   \n",
      "6511       1      0            0  ...        6511  0.056763  0.057261   \n",
      "6512       0      0            0  ...        6512  0.050757  0.052328   \n",
      "6513       0      1            0  ...        6513  0.170601  0.076896   \n",
      "\n",
      "            t3        t4        t5        t6        t7        t8        t9  \n",
      "0     0.023082  0.024851  0.032014  0.084131  0.060399  0.047861  0.099853  \n",
      "1     0.061806  0.095144  0.068057  0.477110  0.054117  0.077907  0.057213  \n",
      "2     0.038066  0.082043  0.074964  0.048033  0.217987  0.227335  0.034323  \n",
      "3     0.042445  0.034457  0.044801  0.039667  0.039551  0.118835  0.067442  \n",
      "4     0.028705  0.027482  0.298594  0.191709  0.173903  0.026904  0.161827  \n",
      "...        ...       ...       ...       ...       ...       ...       ...  \n",
      "6509  0.071439  0.052529  0.052125  0.110842  0.050760  0.303895  0.054362  \n",
      "6510  0.053231  0.074877  0.102638  0.079078  0.078468  0.439172  0.065582  \n",
      "6511  0.058586  0.058671  0.274291  0.059230  0.273952  0.061321  0.099925  \n",
      "6512  0.055337  0.088915  0.113313  0.049831  0.458770  0.078949  0.051801  \n",
      "6513  0.213457  0.036051  0.071391  0.047748  0.064054  0.283878  0.035924  \n",
      "\n",
      "[6514 rows x 966 columns]\n"
     ]
    }
   ],
   "source": [
    "df1 = pd.read_csv(\"Data/PreProcessedData.csv\")\n",
    "df_no_plot = df1.drop('Plot', axis = 1)\n",
    "df2 = pd.read_csv(\"Data/LDA_topics.csv\") #UPDATE THIS TO BE WHATEVER DATA WE GIVE IT\n",
    "df_LDATOPICS = pd.concat([df_no_plot, df2], axis=1)\n",
    "df_LDATOPICS = df_LDATOPICS.drop('Title', axis = 1)\n",
    "print(df_LDATOPICS)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [],
   "source": [
    "df2 = pd.read_csv(\"Data/LDA_topics_synonym.csv\")\n",
    "df_LDATOPICS_synonym = pd.concat([df_no_plot, df2], axis=1)\n",
    "df_LDATOPICS_synonym = df_LDATOPICS_synonym.drop('Title', axis = 1)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [],
   "source": [
    "def test_trainsets(df):\n",
    "    rating = df['IMDbRating']\n",
    "    xdf = df.drop('IMDbRating', axis=1, inplace=False)\n",
    "    \n",
    "    # Split the data into train and test sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(xdf, rating, test_size=0.2, random_state=42)\n",
    "    \n",
    "    X_train_df = pd.DataFrame(X_train)\n",
    "    X_test_df = pd.DataFrame(X_test)\n",
    "    y_train_df = pd.DataFrame(y_train)\n",
    "    y_test_df = pd.DataFrame(y_test)\n",
    "\n",
    "    return X_train_df, y_train_df, X_test_df, y_test_df"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#ROOM FOR PARAMETER TESTING"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.678209176159545\n",
      "0.776840421462601\n",
      "0.732682787022069\n",
      "0.8239868527045442\n",
      "0.7345483812855668\n",
      "0.8302755760643642\n",
      "0.6901474795277426\n",
      "0.7796659473113684\n",
      "0.7152102596700306\n",
      "0.8062892206100271\n",
      "[6.53644   6.2246327 6.232986  ... 5.810945  5.52865   5.972417 ]\n",
      "      IMDbRating\n",
      "5932         5.7\n",
      "1872         6.3\n",
      "1002         6.8\n",
      "6036         3.1\n",
      "5421         7.0\n",
      "...          ...\n",
      "6367         6.2\n",
      "4560         6.5\n",
      "4152         4.6\n",
      "3964         6.2\n",
      "1844         7.4\n",
      "\n",
      "[1303 rows x 1 columns]\n"
     ]
    }
   ],
   "source": [
    "X_train, y_train, X_test, y_test = test_trainsets(df_LDATOPICS)\n",
    "\n",
    "# Create the XGBoost model\n",
    "xgb_model = xgb.XGBRegressor()\n",
    "\n",
    "# Kfold\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=123)\n",
    "\n",
    "# store the score for each fold\n",
    "scores = []\n",
    "\n",
    "mae_scores = []\n",
    "baseline_scores = []\n",
    "# Iterate over the folds\n",
    "for train_index, val_index in kf.split(X_train):\n",
    "    # Split the data into training and validation sets\n",
    "    X_train_fold, X_val_fold = X_train.iloc[train_index], X_train.iloc[val_index]\n",
    "    y_train_fold, y_val_fold = y_train.iloc[train_index], y_train.iloc[val_index]\n",
    "\n",
    "    # Train the model on the training data\n",
    "    xgb_model.fit(X_train_fold, y_train_fold)\n",
    "\n",
    "    # Make predictions on the validation data\n",
    "    y_pred_fold = xgb_model.predict(X_val_fold)\n",
    "    # Compute the MAE score\n",
    "    baseline = mean_absolute_error(y_val_fold, np.array([np.mean(y_train['IMDbRating'])] * len(y_pred_fold)))\n",
    "    mae = mean_absolute_error(y_val_fold, y_pred_fold)\n",
    "    print(mae)\n",
    "    print(baseline)\n",
    "    mae_scores.append(mae)\n",
    "    baseline_scores.append(baseline)\n",
    "\n",
    "# Compute the average MAE score\n",
    "average_mae = sum(mae_scores) / len(mae_scores)\n",
    "average_baseline = sum(baseline_scores) / len(baseline_scores)\n",
    "\n",
    "y_pred = xgb_model.predict(X_test)\n",
    "print(y_pred)\n",
    "print(y_test)\n",
    "results = pd.DataFrame({'Actual': y_test['IMDbRating'], 'Prediction': y_pred})\n",
    "results.to_csv('LDA_Topics_results.csv', index=False)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6905952620026249\n",
      "0.776840421462601\n",
      "0.7194052845868862\n",
      "0.8239868527045442\n",
      "0.7220759663609305\n",
      "0.8302755760643642\n",
      "0.6922737716484436\n",
      "0.7796659473113684\n",
      "0.7190202249446437\n",
      "0.8062892206100271\n",
      "[6.6005907 6.641737  6.3465843 ... 6.058514  5.7030725 6.295929 ]\n",
      "      IMDbRating\n",
      "5932         5.7\n",
      "1872         6.3\n",
      "1002         6.8\n",
      "6036         3.1\n",
      "5421         7.0\n",
      "...          ...\n",
      "6367         6.2\n",
      "4560         6.5\n",
      "4152         4.6\n",
      "3964         6.2\n",
      "1844         7.4\n",
      "\n",
      "[1303 rows x 1 columns]\n"
     ]
    }
   ],
   "source": [
    "X_train, y_train, X_test, y_test = test_trainsets(df_LDATOPICS_synonym)\n",
    "\n",
    "# Create the XGBoost model\n",
    "xgb_model = xgb.XGBRegressor()\n",
    "\n",
    "# Kfold\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=123)\n",
    "\n",
    "# store the score for each fold\n",
    "scores = []\n",
    "\n",
    "mae_scores = []\n",
    "baseline_scores = []\n",
    "# Iterate over the folds\n",
    "for train_index, val_index in kf.split(X_train):\n",
    "    # Split the data into training and validation sets\n",
    "    X_train_fold, X_val_fold = X_train.iloc[train_index], X_train.iloc[val_index]\n",
    "    y_train_fold, y_val_fold = y_train.iloc[train_index], y_train.iloc[val_index]\n",
    "\n",
    "    # Train the model on the training data\n",
    "    xgb_model.fit(X_train_fold, y_train_fold)\n",
    "\n",
    "    # Make predictions on the validation data\n",
    "    y_pred_fold = xgb_model.predict(X_val_fold)\n",
    "    # Compute the MAE score\n",
    "    baseline = mean_absolute_error(y_val_fold, np.array([np.mean(y_train['IMDbRating'])] * len(y_pred_fold)))\n",
    "    mae = mean_absolute_error(y_val_fold, y_pred_fold)\n",
    "    print(mae)\n",
    "    print(baseline)\n",
    "    mae_scores.append(mae)\n",
    "    baseline_scores.append(baseline)\n",
    "\n",
    "# Compute the average MAE score\n",
    "average_mae = sum(mae_scores) / len(mae_scores)\n",
    "average_baseline = sum(baseline_scores) / len(baseline_scores)\n",
    "\n",
    "y_pred = xgb_model.predict(X_test)\n",
    "print(y_pred)\n",
    "print(y_test)\n",
    "results = pd.DataFrame({'Actual': y_test['IMDbRating'], 'Prediction': y_pred})\n",
    "results.to_csv('LDA_Topics_synonym_results.csv', index=False)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
