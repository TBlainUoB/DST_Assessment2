{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Creation and Pre-processing of the dataset"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Firstly, we create a database containing a large variety of films with various features. There is therefore two steps needed: gathering a list of film titles, and making API calls to gather the desired features for each title. There are various APIs available for this purpose.\n",
    "\n",
    "To build the dataframe of film titles, we found that wikipedia conveniently had pages which were in the format\n",
    "https://en.wikipedia.org/wiki/List_of_{country}_films_of_{year}.\n",
    "\n",
    "For example, for british films in 2022:\n",
    "\"This article lists feature-length British films and full-length documentaries that had their premiere in 2022 and were at least partly produced by the United Kingdom. It does not feature short films, medium-length films, made-for-TV films, pornographic films, filmed theater, VR films or interactive films, nor does it include films screened in previous years that have official release dates in 2022.\"\n",
    "\n",
    "All the films in these articles are set out in tables and there is no bias towards only including well performing films.\n",
    "\n",
    "We make an assumption that british and american audiences and trends have a large amount of crossover, and choose to create a database containing all films released between 2000 and 2022 produced in the UK or the US."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "def films_years_country(country, years_from, year_to, start, end):\n",
    "    filmdata = []\n",
    "    start_num = years_from\n",
    "    end_num = year_to\n",
    "    year = list(range(start_num, end_num + 1))\n",
    "\n",
    "    for i in year:\n",
    "        url = (f\"https://en.wikipedia.org/wiki/List_of_{country}_films_of_{str(i)}\")\n",
    "\n",
    "        # Make a GET request to the website\n",
    "        response = requests.get(url)\n",
    "\n",
    "        # Parse the HTML content of the website\n",
    "        soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "        # print(soup)\n",
    "        movie_titles = []\n",
    "        # Find all elements with the class \"movie-title\"\n",
    "        rows = soup.find_all('tr')\n",
    "        for row in rows:\n",
    "            title = row.find('a')\n",
    "            if title:\n",
    "                movie_titles.append(title.text)\n",
    "        #print(movie_titles)\n",
    "        movie_titles = movie_titles[start:]\n",
    "        movie_titles = movie_titles[:len(movie_titles) - end]\n",
    "        print(movie_titles)\n",
    "        for i in movie_titles:\n",
    "            filmdata.append(i)\n",
    "    df = pd.DataFrame(filmdata)\n",
    "    df.to_csv(f\"MovieTitles_{years_from}-{year_to}_{country}.csv\", index=False)\n",
    "    return df\n",
    "\n",
    "\n",
    "df1 = films_years_country(\"British\", 2000, 2022, 19, 35)\n",
    "df2 = films_years_country(\"American\", 2000, 2022, 29, 30)\n",
    "df = pd.concat([df1, df2], axis=0)\n",
    "df.to_csv(\"Data/MovieTitles_British_American_2000_2022.csv\", index=False)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                        0\n",
      "0                Aberdeen\n",
      "1              The Asylum\n",
      "2               The Beach\n",
      "3           Beautiful Joe\n",
      "4                    Best\n",
      "5            Billy Elliot\n",
      "6                   Blood\n",
      "7             Borstal Boy\n",
      "8         Bread and Roses\n",
      "9            Breathtaking\n",
      "10            Chicken Run\n",
      "11               Chocolat\n",
      "12              The Claim\n",
      "13             Complicity\n",
      "14             Essex Boys\n",
      "15            Esther Kahn\n",
      "16  Five Seconds to Spare\n",
      "17         Gangster No. 1\n",
      "18              Gladiator\n",
      "19        The Golden Bowl\n",
      "                                                 0\n",
      "9855                                  Emancipation\n",
      "9856                                 Spoiler Alert\n",
      "9857           Diary of a Wimpy Kid: Rodrick Rules\n",
      "9858                            Darby and the Dead\n",
      "9859                       Lady Chatterley's Lover\n",
      "9860                          The Eternal Daughter\n",
      "9861                           Matilda the Musical\n",
      "9862                               Empire of Light\n",
      "9863    Night at the Museum: Kahmunrah Rises Again\n",
      "9864                                     The Whale\n",
      "9865                      Something from Tiffany's\n",
      "9866                  Detective Knight: Redemption\n",
      "9867                                  The Mean One\n",
      "9868                              Affirm Originals\n",
      "9869                      Avatar: The Way of Water\n",
      "9870                  Puss in Boots: The Last Wish\n",
      "9871                                Amazon Studios\n",
      "9872                                       Babylon\n",
      "9873  Whitney Houston: I Wanna Dance with Somebody\n",
      "9874                             The Pale Blue Eye\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"Data/MovieTitles_British_American_2000_2022.csv\")\n",
    "print(df.head(20))\n",
    "print(df.tail(20))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "It's unlikely this is a complete list, however, we were unable to find any films it had missed. Apart from possibly sequels, we would assume that it does not matter if the list is complete or not."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "The next step is to make API calls for each film in the liat."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Title': 'Shrek 2', 'Year': '2004', 'Rated': 'PG', 'Released': '19 May 2004', 'Runtime': '93 min', 'Genre': 'Animation, Adventure, Comedy', 'Director': 'Andrew Adamson, Kelly Asbury, Conrad Vernon', 'Writer': 'William Steig, Andrew Adamson, Joe Stillman', 'Actors': 'Mike Myers, Eddie Murphy, Cameron Diaz', 'Plot': \"Shrek (Mike Myers) has rescued Princess Fiona (Cameron Diaz), got married, and now is time to meet the parents. Shrek, Fiona, and Donkey (Eddie Murphy) set off to Far, Far Away to meet Fiona's mother and father. But not everyone is happy. Shrek and King Harold (John Cleese) find it hard to get along, and there's tension in the marriage. It's not just the family who are unhappy. Prince Charming (Rupert Everett) returns from a failed attempt at rescuing Fiona, and works alongside his mother, the Fairy Godmother (Jennifer Saunders), to try and find a way to get Shrek away from Fiona.\", 'Language': 'English', 'Country': 'United States', 'Awards': 'Nominated for 2 Oscars. 18 wins & 52 nominations total', 'Poster': 'https://m.media-amazon.com/images/M/MV5BMDJhMGRjN2QtNDUxYy00NGM3LThjNGQtMmZiZTRhNjM4YzUxL2ltYWdlL2ltYWdlXkEyXkFqcGdeQXVyMTQxNzMzNDI@._V1_SX300.jpg', 'Ratings': [{'Source': 'Internet Movie Database', 'Value': '7.3/10'}, {'Source': 'Rotten Tomatoes', 'Value': '89%'}, {'Source': 'Metacritic', 'Value': '75/100'}], 'Metascore': '75', 'imdbRating': '7.3', 'imdbVotes': '470,459', 'imdbID': 'tt0298148', 'Type': 'movie', 'DVD': '05 Nov 2004', 'BoxOffice': '$441,226,247', 'Production': 'N/A', 'Website': 'N/A', 'Response': 'True'}\n"
     ]
    }
   ],
   "source": [
    "# Set the API endpoint URL\n",
    "url = \"http://www.omdbapi.com/\"\n",
    "api_key = \"86325b89\" # Toms API key. Limited to 100,000 requests per day\n",
    "\n",
    "titles = pd.read_csv(\"Data/MovieTitles_British_American_2000_2022.csv\")[\"0\"].to_list()\n",
    "\n",
    "response = requests.get(url, params={\n",
    "        \"apikey\": api_key,\n",
    "        \"t\": titles[4933],\n",
    "        # \"y\": year,\n",
    "        \"plot\": \"full\",\n",
    "        \"type\": \"movie\"\n",
    "    })\n",
    "data = response.json()\n",
    "print(data)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "The API calls return useful data about each film. This is a lot of features which would be possible to use.\n",
    "Since the project is focused on NLP, we choose to extract the title and the plot. We also extract the year, genre, and the IMDb Rating, which is going to be our target. There may be other features such as Runtime AgeRating Director ... which may be useful for our prediction model, however, we chose to limit the feature space and make the project more about how we process the title and plot features to get a good prediction."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Set the API endpoint URL\n",
    "url = \"http://www.omdbapi.com/\"\n",
    "api_key = \"86325b89\" # Toms API key. Limited to 100,000 requests per day\n",
    "\n",
    "titles = pd.read_csv(\"Data/MovieTitles_British_American_2000_2022.csv\")[\"0\"].to_list()\n",
    "\n",
    "movie_data = []\n",
    "count = 0\n",
    "\n",
    "for i in titles:\n",
    "    response = requests.get(url, params={\n",
    "        \"apikey\": api_key,\n",
    "        \"t\": i,\n",
    "        # \"y\": year,\n",
    "        \"plot\": \"full\",\n",
    "        \"type\": \"movie\"\n",
    "    })\n",
    "    data = response.json()\n",
    "    #print(data)\n",
    "    count += 1\n",
    "    if count % 50 == 0:\n",
    "        response = data[\"Response\"]\n",
    "        print(f\"{response}, {count} out of {len(titles)}\")\n",
    "\n",
    "    if data[\"Response\"] == 'True':\n",
    "        movie_data.append({\n",
    "            \"IMDbRating\": data[\"imdbRating\"],\n",
    "            \"Title\": data[\"Title\"],\n",
    "            \"Year\": data[\"Year\"],\n",
    "            \"Genre\": data[\"Genre\"],\n",
    "            \"Plot\": data[\"Plot\"],\n",
    "            \"Actors\": data[\"Actors\"],\n",
    "        })\n",
    "\n",
    "# Create a DataFrame from the movie data\n",
    "df = pd.DataFrame(movie_data)\n",
    "df.to_csv(\"Data/MovieDatabase_British_American_2000_2021.csv\", index=False)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Some of these API calls do inevitably get the incorrect movie. There might be two films which have the same name and our api lookup picks the wrong one, such as classical films with modern day remakes. We assume that this does not affect our overall predictions. Some films also fail with the API lookup and we lose these from our database but again, it does not seem essential for this project to have a perfect complete database.\n",
    "\n",
    "Another issue is that some films have N/A for some of the features we wish to use, such as the plot. Rather than to set this to some default value, we choose to remove these films from the database.\n",
    "\n",
    "There are 26 genres in total so we One-hot-encode these."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [],
   "source": [
    "def RemoveNA(df):\n",
    "    df = df.replace(\"N/A\", np.nan)\n",
    "    df = df.dropna()\n",
    "    return df\n",
    "\n",
    "\n",
    "def RemoveDuplicates(df):\n",
    "    df = df.drop_duplicates()\n",
    "    return df\n",
    "\n",
    "\n",
    "def OHE_Genre(df):\n",
    "    genres = list(set(df[\"Genre\"].tolist()))\n",
    "\n",
    "    film_genres = df['Genre'].str.split(',', expand=True).replace(\" \", \"\")\n",
    "    film_genres = film_genres.apply(lambda x: x.str.strip())\n",
    "\n",
    "    # One-hot encode the new genre columns and append to the film dataframe\n",
    "    genre_dummies = pd.get_dummies(film_genres.stack()).groupby(level=0).sum()\n",
    "    film_df = pd.concat([df, genre_dummies], axis=1)\n",
    "\n",
    "    # drop original genre column\n",
    "    film_df.drop('Genre', axis=1, inplace=True)\n",
    "    return film_df"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "We now need to decide how to process the actors.\n",
    "By logic, we think that an actor who has only appeared in very little films will not be a good predictor for the rating of a new film. By setting the minimum amount of films an actor has appeared in to 5, we reduce the number of actors in our database to 927, which we can then one hot encode. It was difficult to conclude to what approach was best when deadling with the actors column. Dimensionality reduction methods such as PCA could work, however, OHE was manageable and despite adding 927 columns to our database, will not affect model performance."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "outputs": [],
   "source": [
    "def OHE_actors(df):\n",
    "    # Get all unique actors in the dataset\n",
    "    film_actors = df['Actors'].str.split(',', expand=True).replace(\" \", \"\")\n",
    "    film_actors = film_actors.apply(lambda x: x.str.strip())\n",
    "\n",
    "    actor_dummies = pd.get_dummies(film_actors.stack()).groupby(level=0).sum()\n",
    "\n",
    "    # Sum the number of movies each actor has appeared in\n",
    "    actor_counts = actor_dummies.sum(axis=0)\n",
    "\n",
    "    # Filter out actors with less than 5 movie appearances\n",
    "    actor_counts = actor_counts[actor_counts >= 5]\n",
    "\n",
    "    # Select only the one-hot encoded columns for actors with more than 5 movie appearances\n",
    "    actor_dummies = actor_dummies[actor_counts.index]\n",
    "    df = pd.concat([df, actor_dummies], axis=1)\n",
    "    df.drop('Actors', axis=1, inplace=True)\n",
    "    return df\n",
    "\n",
    "df = pd.read_csv(\"Data/MovieDatabase_British_American_2000_2021.csv\")\n",
    "df = RemoveDuplicates(df)\n",
    "df = RemoveNA(df)\n",
    "df = OHE_Genre(df)\n",
    "df = OHE_actors(df)\n",
    "df = df[df['Year'] >= 2000]\n",
    "\n",
    "df.to_csv(\"Data/PreProcessedData.csv\", index=False)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Since we have this database, Lets see who the best and worst actors that have appeared in 5 or more films this century are."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"Data/PreProcessedData.csv\")\n",
    "targets = df['IMDbRating']\n",
    "df = df.iloc[:, 30:]\n",
    "\n",
    "actor_names = df.columns.tolist()\n",
    "num_films = 6731\n",
    "rating_data = []\n",
    "for actor in actor_names:\n",
    "    sum = 0\n",
    "    films = 0\n",
    "    lowest = 10\n",
    "    highest = 0\n",
    "    for film in range(num_films):\n",
    "        if df[actor][film] == 1:\n",
    "            sum += targets[film]\n",
    "            films += 1\n",
    "            if targets[film] > highest:\n",
    "                highest = targets[film]\n",
    "            if targets[film] < lowest:\n",
    "                lowest = targets[film]\n",
    "    rating_data.append({\n",
    "        'Actor': actor,\n",
    "        'AvgIMDb': round(sum/films, 2),\n",
    "        'Num_Films': films,\n",
    "        'Spacer': \"---\",\n",
    "        'Lowest_Rated': lowest,\n",
    "        'Highest_Rated': highest})\n",
    "df = pd.DataFrame(rating_data)\n",
    "\n",
    "sorted_df = df.sort_values('AvgIMDb')\n",
    "sorted_df = sorted_df.iloc[::-1]\n",
    "sorted_df.to_csv('Actor_Rankings.csv', index=False)\n",
    "\n",
    "print(sorted_df.head(20))\n",
    "print(sorted_df.tail(20))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
