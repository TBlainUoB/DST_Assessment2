{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "6b1f2285",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\Danie\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping taggers\\averaged_perceptron_tagger.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('averaged_perceptron_tagger')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "id": "b6516f63",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_7396\\4125471731.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpreprocessing\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mLabelEncoder\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mInput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mDense\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mLambda\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodels\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mModel\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlosses\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mbinary_crossentropy\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     19\u001b[0m \"\"\"\n\u001b[0;32m     20\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mdistribute\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 21\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmodels\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     22\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minput_layer\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mInput\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msequential\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mSequential\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\models\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 18\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfunctional\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mFunctional\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     19\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msequential\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mSequential\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtraining\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mModel\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\engine\\functional.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mwarnings\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 24\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mv2\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     25\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mbackend\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from keras.layers import Input, Dense, Lambda\n",
    "from keras.models import Model\n",
    "from keras.losses import binary_crossentropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "id": "f74c6b94",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'maya is a quickwitted young woman who comes over the mexican border without papers and makes her way to the la home of her older sister rosa rosa gets maya a job as a janitor a nonunion janitorial service has the contract the foulmouthed supervisor can fire workers on a whim and the serviceworkers union has assigned organizer sam shapiro to bring its justice for janitors campaign to the building sam finds maya a willing listener shes also attracted to him rosa resists she has an ailing husband to consider the workers try for public support management intimidates workers to divide and conquer rosa and maya as well as workers and management may be set to collide'"
      ]
     },
     "execution_count": 286,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data=pd.read_csv('Movie_database_BritishAmerican2000-2021.csv')\n",
    "plots=data.Plot\n",
    "test=plots[8]\n",
    "test=re.sub(r'[^\\w\\s]', '', test)\n",
    "test=test.lower()\n",
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "id": "33f41241",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "#Switching out hyphons for spaces\n",
    "plots=[str(plots[num]).replace('-',' ') for num in range(len(plots))]\n",
    "# Removing punctuation\n",
    "plots=[re.sub(r'[^\\w\\s]','', str(plots[num])) for num in range(len(plots))]\n",
    "# Lowercasing the words\n",
    "plots=[str(plots[num]).lower() for num in range(len(plots))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "id": "6f63024d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "#Removing stop words and tokenising\n",
    "\n",
    "#Define english stop words\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "#Define function for removing stop words + tokenizing\n",
    "def stopntokenize(text):\n",
    "    word_tokens = word_tokenize(text)\n",
    "    new_text = []\n",
    "    for w in word_tokens:\n",
    "        if w not in stop_words:\n",
    "            new_text.append(w)\n",
    "    return(new_text)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "id": "0e78e1f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Stemming and Lemmatizing\n",
    "#from nltk.stem import PorterStemmer\n",
    "\n",
    "#Ps=PorterStemmer()\n",
    "#test4=[Ps.stem(test4[num]) for num in range(len(test4))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "id": "47ffe75d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import WordNetLemmatizer \n",
    "lemmatizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "id": "1e9f5f69",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Only including important words, (i.e. nouns, verbs, adjectives and adverbs)\n",
    "\n",
    "def wordremover(tokens):\n",
    "    wordtypes = nltk.pos_tag(tokens)\n",
    "    tokens_new=[]\n",
    "    for i in range(len(tokens)):\n",
    "        if wordtypes[i][1] in ['NN','NNP','JJ','JJR','JJS','RB','RBR','RBS','VB','VBD','VBG','VBN','VBP','VBZ']:\n",
    "            tokens_new.append(tokens[i])\n",
    "    return(tokens_new)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82e0796a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "id": "0ad99c20",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenizer(text):\n",
    "    token=stopntokenize(text)\n",
    "    token=[lemmatizer.lemmatize(token[num]) for num in range(len(token))]\n",
    "    token=wordremover(token)\n",
    "    token=list(dict.fromkeys(token))\n",
    "    return(token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "id": "697f8322",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'in the small town of san dimas a few miles away from los angeles there are two nearly brain dead teenage boys going by the names of bill s preston esq and ted theodore logan they have a dream together of starting their own rock and roll band called the wyld stallyns unfortunately they are still in high school and on the verge of failing out of their school as well and if they do not pass their upcoming history report they will be separated as a result of teds father sending him to military school but what bill and ted do not know is that they must stay together to save the future so a man from the future named rufus came to help them pass their report so both bill and ted decided to gather up historical figures which they need for their report they are hoping that this will help them pass their report so they can stay together'"
      ]
     },
     "execution_count": 292,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "M=1003\n",
    "plots[M]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "id": "fd2c01cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['small',\n",
       " 'town',\n",
       " 'san',\n",
       " 'dimas',\n",
       " 'mile',\n",
       " 'away',\n",
       " 'los',\n",
       " 'nearly',\n",
       " 'brain',\n",
       " 'dead',\n",
       " 'teenage',\n",
       " 'boy',\n",
       " 'going',\n",
       " 'name',\n",
       " 'bill',\n",
       " 'preston',\n",
       " 'esq',\n",
       " 'ted',\n",
       " 'theodore',\n",
       " 'logan',\n",
       " 'dream',\n",
       " 'together',\n",
       " 'starting',\n",
       " 'rock',\n",
       " 'roll',\n",
       " 'band',\n",
       " 'called',\n",
       " 'wyld',\n",
       " 'stallyns',\n",
       " 'unfortunately',\n",
       " 'still',\n",
       " 'high',\n",
       " 'school',\n",
       " 'verge',\n",
       " 'failing',\n",
       " 'well',\n",
       " 'upcoming',\n",
       " 'history',\n",
       " 'report',\n",
       " 'separated',\n",
       " 'result',\n",
       " 'father',\n",
       " 'sending',\n",
       " 'military',\n",
       " 'know',\n",
       " 'stay',\n",
       " 'save',\n",
       " 'future',\n",
       " 'man',\n",
       " 'named',\n",
       " 'rufus',\n",
       " 'came',\n",
       " 'help',\n",
       " 'pas',\n",
       " 'decided',\n",
       " 'gather',\n",
       " 'historical',\n",
       " 'figure',\n",
       " 'need',\n",
       " 'hoping']"
      ]
     },
     "execution_count": 293,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer(plots[M])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "id": "75ebe1a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "39.80225"
      ]
     },
     "execution_count": 254,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x=[]\n",
    "for i in range(4000):\n",
    "    x.append(len(tokenizer(plots[i])))\n",
    "\n",
    "sum(x)/4000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "id": "1c8fd33f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'in the bronx joe sir billy connolly bn irish good guy gets bbd news twice the sbme dby he hbs b brbin tumor bnd his wife wbnts b divorce sbying hes dull bnd lbcks bdventure with her fbthers blessing joe tbkes off for bdventures in the weeks before risky surgery in louisville hes lbtched onto by hush shbron stone b tblkbtive belle with two kids big debts to b nbsty bookie bnd few prospects even bfter she stebls his wbllet joe offers temporbry help bonds with her kids bnd fbces down the bookie soon hush joe bnd the kids bre on the run towbrd lbs vegbs the bookies on their tbil so bre some bronx bbd guys cbncer lurks hush hbs her gbmbling jones bnd the kids wbnt stbbility cbn this work out'"
      ]
     },
     "execution_count": 277,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plots[3].replace('a','b')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
